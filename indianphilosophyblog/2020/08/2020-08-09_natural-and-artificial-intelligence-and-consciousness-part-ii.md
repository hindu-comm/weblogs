+++
title = "Natural and Artificial"
full_title = "Natural and Artificial Intelligence, and Consciousness, Part II"
date = "2020-08-09"
upstream_url = "https://indianphilosophyblog.org/2020/08/09/natural-and-artificial-intelligence-and-consciousness-part-ii/"

+++
Source: [here](https://indianphilosophyblog.org/2020/08/09/natural-and-artificial-intelligence-and-consciousness-part-ii/).

Natural and Artificial Intelligence, and Consciousness, Part II

The Indian tradition is replete with modeling of human experience. In
the previous post I discussed how Sāṃkhya’s model of mind, body, and
consciousness might be used to rethink the conceptualization of
evolutionary theory and neuroscience. I argued that the ontology of
Sāṃkhya would suggest that the interactions between mind and body are
entirely within the scope of “nature” and that “consciousness” is
outside this natural system, yet it gives the appearance of
consciousness within nature. How might this ontology look at AI?

There are two forms of AI that exist right now of which I am familiar;
this discussion excludes the types of AI one might envision we shall
develop in the future. The first is neuralinks that would connect the
human brain to external computers, phones, machines, bodily limbs, etc.;
and the second is independent robots that can execute complex actions
and use machine learning. Will we ever see the types of robots in
science fiction movies? I do not have a strong view on that, but I do
believe that various forms of AI will be used for travel, sales,
agriculture, and human services will be used more and more in the near
future.

From the perspective of Sāṃkhya, all forms of AI would be considered
“natural” in the sense that they part of nature or prakṛti; even human
artifacts are still natural in the broad and general sense that Sāṃkhya
might be thought about in English. The word “artificial” as it is used
in AI often seems to be used in the sense of a human creation that is
distinct from the biological structures created by “natural” processes
like natural selection.

But I have two specific thoughts on AI. The first is that Sāṃkhya has a
robust concept of “intelligence” and in their view the intelligence
functions as an entirely natural and yet unconscious manner. The
intellect (e.g. buddhi) requires the consciousness to function, but
consciousness exists independently from the intellect (the innate
features of the consciousness is a matter of discussion among different
scholars). Generally speaking, intellect in Sāṃkhya does not imply an
independent or self-directed will; its being is activated if and when it
is connected to a particular consciousness, but the consciousness is the
being that provides intellect with the ability to function in the
various ways that it can function. The intellect could not develop a
self-reflexive state of awareness, since that portion of cognition is
provided by the consciousness which uses or observes the functions of
intellect when it is in connection with a natural mind-body complex.

The notion that intelligence functions when in connection with a
consciousness brings me to the second thought I have on Sāṃkhya. The ego
is what connects the nonphysical and eternal being of the consciousness
to the natural and ever changing mind-body complex. The birth of a human
or animal in Sāṃkhya is essentially the attachment of a particular
consciousness to a particular mind-body complex through the power of the
ego. Thus, for Sāṃkhya, the creation of a robot that has AI would
require the ego to attach to said robot. The question, then, for Sāṃkhya
is: is it possible for humans to create a machine to which a
consciousness can attach via the ego?

Readers of this blog, however, must also be familiar with the Buddhist
theory of *pratītyasaṃutpāda*, or the co-dependent origination; the
Nyāya theory of the *padārtha*, or that reality is composed of distinct
categories that correspond to specific words; the Vaiśeṣika atomic
theory; and there are other theories in Jainism and a wide range of
distinctions within those mentioned. Would these conceptual schemes look
at AI differently? Would they raise different problems? My goal here was
not to go into these theories in any depth, but ask a more general
question about the term “artificial” and how that would be thought of in
a conceptual scheme that see all forms of intellect as natural; and to
think about the problem of the ego as it pertains to the creation of AI
machines or robots.
