+++
title = "The Cultural Evolution"
full_title = "The Cultural Evolution of Language"
date = "2010-03-10"
upstream_url = "https://www.gnxp.com/WordPress/2010/03/10/the-cultural-evolution-of-language/"

+++
Source: [here](https://www.gnxp.com/WordPress/2010/03/10/the-cultural-evolution-of-language/).

The Cultural Evolution of Language

One of the major shifts in thinking about language came in 1990, when [Steven Pinker](https://en.wikipedia.org/wiki/Steven_Pinker) and [Paul Bloom](https://en.wikipedia.org/wiki/Paul_Bloom_%28psychologist%29) published their groundbreaking paper: [Natural language and natural selection](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.116.4044&rep=rep1&type=pdf). In it, they argue natural selection was the central process in shaping the biological structures underpinning language. Since then, the field of language evolution has blossomed into a truly multidisciplinary subject. Yet now, I believe we are in the process of undergoing another paradigm shift: incorporating cultural evolution.

For some features, particularly the physical capacity to produce and receive multiple vocalizations, there is ample evidence for specialisation: a descended larynx, thoracic breathing, and several distinct hearing organs. Given that these features are firmly in the domain of biology, it makes intuitive sense to apply the theory of natural selection to solve the problem: humans are specially adapted to the production and reception of multiple vocalizations. Yet Pinker and Bloom’s argument is found somewhat wanting when extended to incorporate the notion that natural selection shaped specialised mental organs, or modules, for acquiring language. First and foremost, the notion of a putative [*language acquisition device*](https://en.wikipedia.org/wiki/Language_acquisition_device) (commonly referred to as *LAD*) is not an established fact: rather, it’s derived from [Noam Chomsky](https://en.wikipedia.org/wiki/Noam_Chomsky)’s arguments from the *[poverty of the stimulus](https://en.wikipedia.org/wiki/Poverty_of_the_stimulus)* (POTS) and assumptions that all languages are essentially the same in structure, but differ in their sound systems and vocabularies.

As such, under the stewardship of Pinker, Chomsky and others, the origin, evolution and acquisition of language is primarily seen as a biological question to be answered. Whilst it is certain that biology plays a role in the evolution of language, its exact purpose is still contentious in light of new research emerging from theories into cultural evolution. A notable instance came at the 2009 [*CogSci conference*](http://csjarchive.cogsci.rpi.edu/Proceedings/2009/), where some of the leading researchers into the cultural evolution of language [met up at a symposium](http://csjarchive.cogsci.rpi.edu/Proceedings/2009/papers/491/index.html), namely: [Nick Chater](http://www.psychol.ucl.ac.uk/people/profiles/chater_nick.htm) (philosophy), [Thomas L. Griffiths](http://cocosci.berkeley.edu/tom/) (Bayesian analyses), [Simon Kirby](http://www.ling.ed.ac.uk/%7Esimon/) (evolutionary psycholinguistics) and [Morten H. Christiansen](http://www.psych.cornell.edu/people/Faculty/mhc27.html) (molecular genetics). Each of these individuals are key influences on my own thinking in regards to language evolution (Simon Kirby was formerly my course supervisor at Edinburgh), and I think it is worthwhile to dedicate a few paragraphs discussing their ideas.

**Cultural Induction and Language Acquisition (Chater)**

Consider the following question posed by Chater & Christiansen (in press): “Suppose that some natural process yields the sequence 1, 2, 3… How does it continue?” If we put aside our own, highly coordinated learning mechanisms, then the sequence may: oscillate (1, 2, 3, 2, 1, 2, 3, 2, 1…), become stuck (1, 2, 3, 3, 3, 3…), exhibit a Fibonacci structure (1, 2, 3, 5, 8…). In fact, given the scarcity of data, we can yield an infinite array of answers. This is an example of N-induction, which may be described as “induction about the natural world, \[where\] data is generated by some external source, and the learner attempts to predict how it continues”.

However, if you happen to be a reader of this site, the overwhelming likelihood is that the continuation of 1, 2, 3 would be: 4, 5, 6… This is an example of C-induction, where the objective is to coordinate your predictions with other learners to produce the same results. But what’s C-induction’s relevance to the acquisition of language? As Chater explains:

> Thus, in language acquisition, children receive partial linguistic > input, and must generalize to many new linguistic structures – but the > standard of correctness is to generalize in the same way as other > learners. To the extent that learners have the same biases and prior > experience, this dramatically simplifies the learning problem, because their generalizations will typically agree. More generally, language evolution itself can be viewed as the accretion of successive generalizations upon which learners converge.

**Uncovering Inductive Biases through Cultural Evolution (Griffiths)**

Looking at the relationship between the inductive biases of individual learners and the outcome of cultural evolution is something being primarily explored through computational modelling. Specifically, Griffiths argues that by modelling “learning as [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference) \[it\] provides the opportunity to explore this relationship, making the inductive biases of learners transparent through a prior distribution”. Here, the role of learners is to select a hypothesis *h* on the basis of its posterior probability when exposed to data *d*:

[![](https://i0.wp.com/www.gnxp.com/wp/wp-content/uploads/2010/03/bayesian.jpg?resize=180%2C53 "bayesian")![](https://i0.wp.com/www.gnxp.com/wp/wp-content/uploads/2010/03/bayesian.jpg?resize=180%2C53 "bayesian")](https://i0.wp.com/www.gnxp.com/wp/wp-content/uploads/2010/03/bayesian.jpg)

*P*(*d*\|*h*) provides a statistical likelihood of the data *d* being produced under a certain hypothesis *h*, with *P*(*h*) equalling the prior probability of each hypothesis. When applied to models of language and iterated learning (see below), both hypotheses are considered to be the set of possible grammars, whilst the data consists of sets of utterances required to induce a language. Importantly, the prior probability distribution over grammars is the learning bias, which may be domain-specific or domain-general. A critical component of Bayesian learning, and still a point of contention, stems from the role of prior biases and how much influence they exert over a language’s evolutionary trajectory.

**Language Evolution through Iterated Learning (Kirby)**

Much of the literature regarding Iterated Learning focuses on a computational modelling approach, where “the central idea behind the ILM \[Iterated Learning Model\] is to model directly the way language exists and persists via two forms of representation” (Kirby & Hurford, 2002, pg. 123). These [two forms](https://en.wikipedia.org/wiki/Transformational_grammar#.22I-Language.22_and_.22E-Language.22) consist of an *I-Language* (the internal representation of language as a pattern of neural connections) and an *E-Language* (the external representation of language as sets of utterances). This cycle of continued production and induction is used to understand how the evolution of structure emerges from non-linguistic communication systems and how language changes from one form into another.

To briefly summarise, these models contain a single agent who is taught an initial random language (consisting of mappings between meanings and signals). The output of the agent is then used to teach the next generation, and so on. After numerous generational turnovers of teachers and observers, some of these models provide an intriguing insight into the emergence of linguistic phenomena such as [*compositionality*](http://plato.stanford.edu/entries/compositionality/) and *regularity*.

A common theme running through a wide array of these Iterated Learning studies emphasises language as being a compromise between two factors: the biases of learners, and constraints during language transmission. What is perhaps fundamental to this view is encapsulated in the second constraint: that the transmission is a mediating force in the shaping of language. For instance, Kirby & Hurford (2002) show how the infinite expressivity found in languages is a result of the finite set of data presented during acquisition. With this *transmission bottleneck* restricting the amount of data presented, learners must generalise in order to learn the data, but not to the extent where the language is one signal for all possible meanings. Tempering maximal expressivity with generalisation provides an adequate explanation for recursive compositionality, without appealing to the need for an intricately specified *LAD*. As Zuidema (2003) succinctly put it: “the poverty of the stimulus solves the poverty of the stimulus”.

These modelling observations are backed up by experiments utilising real human learners. As Kirby notes:

> By placing the artificial language learning paradigm within a cultural > transmission framework, we can observe the evolution of languages in > the laboratory (Kirby, Cornish & Smith, 2008). Results from these > experiments show that linguistic structure does indeed emerge from initially random systems, and furthermore that this process is non-intentional. In other words, this cultural process provides “design without a designer” just as biological evolution does.

**Genetic Constraints on Cultural Evolution of Language (Christiansen)**

Coming full circle and we’re back to what Steven Pinker and Paul Bloom originally discussed: that of the genetic bases underlying language. Whereas previously, language was seen as a highly specified organ, akin to the visual system, new research highlights the importance of domain-general mechanisms in shaping language. The example Christiansen uses is that of sequential learning: here, both sequential learning and language involve “the extraction and further processing of discrete elements occurring in complex temporal sequences”. On the basis of previous simulation work, showing that constraints on sequential learning can shape the trajectory of linguistic structure, a recent molecular genetics study by Tomblin *et al*. (2007) found:

> \[…\] that common allelic variations in the FOXP2 gene are associated > with differences in sequential learning (as measured by a > serial-response time task) and language… \[suggesting\] that FOXP2 > influences systems that are important to the development of both sequential learning and language, supporting the hypothesis that language may have been shaped through cultural evolution constrained by underlying mechanisms for sequential learning.

It’s important to note that I’m not necessarily in complete agreement with some of the conclusions coming from this research (a point I’ll pick up in another post). I just wanted to give you an indicator as to the depth of work taking place in examining the cultural evolution of language.

**Main citation:** Cultural Evolution of Language: Implications for Cognitive Science. *CogSci 2009 Conference*. PDF Link: <http://csjarchive.cogsci.rpi.edu/Proceedings/2009/papers/491/paper491.pdf>

**Other citations:**

N. Chater & M. Christiansen. Language Acquisition meets Language Evolution. *Cognitive Science*, 2009; DOI: 10.1111/j.1551-6709.2009.01049.x

S. Kirby & J. Hurford. The Emergence of Linguistic Structure: An overview of the Iterated Learning Model. In Angelo Cangelosi and Domenico Parisi, editors, [*Simulating the Evolution of Language*](http://www.isrl.uiuc.edu/%7Eamag/langev/pubtype/inbook_SimulatingtheEvolutionofLanguage.html), 2002; 121-148.

Zuidema. How the poverty of the stimulus solves the poverty of the stimulus. In Suzanna Becker and Sebastian Thrun and Klaus Obermayer, editors, [*Advances in Neural Information Processing Systems 15 (Proceedings of NIPS’02)*](http://www.isrl.uiuc.edu/%7Eamag/langev/pubtype/inproceedings_AdvancesinNeuralInformationProcessingSystems15ProceedingsofNIPS02.html), 2003.

J.B. Tomblin, *et al.* Association of FOXP2 genetic markers with
procedural learning and language. Poster presented at the 57th
Annual Meeting of the American Society of Human Genetics, San Diego, CA. 2007.

### Related Posts:

- [The Evolution of Symbolic
  Language](https://www.gnxp.com/WordPress/2010/03/19/the-evolution-of-symbolic-language/) - [A correlation between acacia trees and tonal
  languages?](https://www.gnxp.com/WordPress/2013/01/25/a-correlation-between-acacia-trees-and-tonal-languages/) - [Podcasts about language as a complex adaptive
  system](https://www.gnxp.com/WordPress/2010/04/11/podcasts-about-language-as-a-complex-adaptive-system/) - [Language and the postgenomic
  era](https://www.gnxp.com/WordPress/2006/04/11/language-and-the-postgenomic-era/) - [The evolution of
  gestures](https://www.gnxp.com/WordPress/2007/04/30/the-evolution-of-gestures/) - [Carl on
  language](https://www.gnxp.com/WordPress/2005/02/26/carl-on-language/)

### *Related*

[](https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fwww.gnxp.com%2FWordPress%2F2010%2F03%2F10%2Fthe-cultural-evolution-of-language%2F&linkname=The%20Cultural%20Evolution%20of%20Language "Facebook")[](https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fwww.gnxp.com%2FWordPress%2F2010%2F03%2F10%2Fthe-cultural-evolution-of-language%2F&linkname=The%20Cultural%20Evolution%20of%20Language "Twitter")[](https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fwww.gnxp.com%2FWordPress%2F2010%2F03%2F10%2Fthe-cultural-evolution-of-language%2F&linkname=The%20Cultural%20Evolution%20of%20Language "Email")[](https://www.addtoany.com/share)
